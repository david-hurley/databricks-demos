{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c4ea0ef-ff6f-44f4-9b7a-6b4f21c8ffe7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install databricks-vectorsearch\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d24273b-3a47-4e0a-9110-94898718e894",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from pyspark.sql import SparkSession\n",
    "from databricks.vector_search.client import VectorSearchClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8321cfb9-c56f-4e21-99dc-8700f664b343",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Update this Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "926a139f-ad4a-4335-9aae-ff0de87fc71e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Update this to YOUR catalog and schema name\n",
    "catalog = \"users\"\n",
    "schema = \"david_hurley\"\n",
    "\n",
    "# This is the path to the cloned artifacts\n",
    "# TODO: This could instead be added to a Managed Volume and subsequent code repointed\n",
    "path_to_artifacts = \"/Workspace/Users/hurleyldave2@gmail.com/databricks-demos/turnaround-agent/artifacts\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b858b880-a331-4137-9ca5-e5a46a5712b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Create Synthetic Table Data\n",
    "\n",
    "- Create relation between plant, equipment, and sensors monitoring equipment\n",
    "- Create fake sensor data and alarm thresholds for sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02cb5c08-873b-429d-9096-053c2f50beea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plant_equipment_relations_table_name = \"plant_equipment_relations\"\n",
    "\n",
    "df = spark.createDataFrame([\n",
    "    (\"A\", \"Heat Exchanger 1\", [1, 2]),\n",
    "    (\"A\", \"Heat Exchanger 2\", [3]),\n",
    "    (\"A\", \"Tube Bundle 1\", [5]),\n",
    "    (\"B\", \"Heat Exchanger 1\", [7, 8]),\n",
    "], [\"plantId\", \"equipmentName\", \"sensorIds\"])\n",
    "\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {catalog}.{schema}.{plant_equipment_relations_table_name}\")\n",
    "\n",
    "df.write.mode('overwrite').saveAsTable(f\"{catalog}.{schema}.{plant_equipment_relations_table_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0e99a4d-3217-45b0-9d80-06f4fed1b36b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sensor_temperature_table_name = \"sensor_temperature\"\n",
    "\n",
    "df = spark.createDataFrame([\n",
    "    (1, 32.5), \n",
    "    (1, 33.1), \n",
    "    (1, 37.9), \n",
    "    (2, 25.2), \n",
    "    (2, 26.5), \n",
    "    (2, 30.1), \n",
    "    (3, 41.5), \n",
    "    (3, 27.2), \n",
    "    (3, 30.1), \n",
    "    (5, 75.2), \n",
    "    (5, 76.1), \n",
    "    (5, 99.1), \n",
    "    (7, 10.0), \n",
    "    (7, 15.0), \n",
    "    (7, 24.4), \n",
    "    (8, 54.6), \n",
    "    (8, 56.1), \n",
    "    (8, 52.3)\n",
    "], [\"sensorId\", \"temperature\"])\n",
    "\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {catalog}.{schema}.{sensor_temperature_table_name}\")\n",
    "\n",
    "df.write.mode('overwrite').saveAsTable(f\"{catalog}.{schema}.{sensor_temperature_table_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "baacaade-8ce0-4204-a253-8adefeb4907d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sensor_alarm_threshold_temperature_table_name = \"sensor_alarm_threshold_temperature\"\n",
    "\n",
    "df = spark.createDataFrame([\n",
    "    (1, 35),\n",
    "    (2, 28),\n",
    "    (3, 45),\n",
    "    (5, 100),\n",
    "    (7, 22),\n",
    "    (8, 64)\n",
    "], [\"sensorId\", \"alarmThresholdTemperature\"])\n",
    "\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {catalog}.{schema}.{sensor_alarm_threshold_temperature_table_name}\")\n",
    "\n",
    "df.write.mode('overwrite').saveAsTable(f\"{catalog}.{schema}.{sensor_alarm_threshold_temperature_table_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d463818b-1497-455e-b74d-4115ae66d65b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Create Unity Catalog Functions\n",
    "- Get relationship between plant, equipment, and sensors\n",
    "- Get temperature data for a sensor\n",
    "- Get alarm settings for a sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a944e35-2bd7-4870-885a-2ea66589fe85",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE FUNCTION {catalog}.{schema}.get_plant_equipment_relationship(\n",
    "  plant_id STRING COMMENT 'Id of the plant to lookup. Example: \"A\"',\n",
    "  equipment_name STRING COMMENT 'Name of the equipment to lookup. Example: \"Heat Exchanger 1\"'\n",
    ")\n",
    "RETURNS TABLE\n",
    "COMMENT 'Returns the relation of plant to equipment to sensors'\n",
    "RETURN\n",
    "  SELECT *\n",
    "  FROM {catalog}.{schema}.{plant_equipment_relations_table_name} \n",
    "  WHERE plantId = plant_id\n",
    "    AND equipmentName ILIKE equipment_name;\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "420bcfa9-d89f-4620-af33-5bd5968f87d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE FUNCTION {catalog}.{schema}.get_sensor_temperatures(\n",
    "  sensor_id INT COMMENT 'Id of the sensor to lookup. Example: 1'\n",
    ")\n",
    "RETURNS TABLE\n",
    "COMMENT 'Returns the temperature data for a given sensor'\n",
    "RETURN SELECT * \n",
    "  FROM {catalog}.{schema}.{sensor_temperature_table_name} \n",
    "  WHERE sensorId = sensor_id;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8bb3d5b-4f6e-4c62-9784-2f5f99064721",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE FUNCTION {catalog}.{schema}.get_sensor_alarm_threshold_temperature(\n",
    "  sensor_id INT COMMENT 'Id of the sensor to lookup; Example: 1'\n",
    ")\n",
    "RETURNS TABLE\n",
    "COMMENT 'Returns the alarm threshold temperature for a given sensor'\n",
    "RETURN SELECT alarmThresholdTemperature\n",
    "  FROM {catalog}.{schema}.{sensor_alarm_threshold_temperature_table_name} \n",
    "  WHERE sensorId = sensor_id;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "46350e4d-cbbd-4ab3-8971-3caa471ab663",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Create Vector Search Database\n",
    "- Create table of markdown text and metadata\n",
    "- Create vector search endpoint\n",
    "- Create vector search index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c137638-d35e-473e-ae23-70a466b9e968",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "inspection_report_table_name = \"turnaround_inspection_reports\"\n",
    "\n",
    "# TODO: This should instead by dynamic and point to a Volume\n",
    "file_names = [\n",
    "    \"inspection_report_plantA_heat_exchanger_1.md\",\n",
    "    \"inspection_report_plantA_heat_exchanger_2.md\",\n",
    "    \"inspection_report_plantA_tube_bundle_1.md\",\n",
    "    \"inspection_report_plantB_heat_exchanger_1.md\"\n",
    "]\n",
    "\n",
    "for idx, file_name in enumerate(file_names):\n",
    "    with open(f\"{path_to_artifacts}/{file_name}\", \"r\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "    # Extract metadata using regex\n",
    "    plant_id = re.search(r\"\\*\\*Plant ID\\*\\*: (.+)\", text).group(1).strip()\n",
    "    equipment_name = re.search(r\"\\*\\*Equipment\\*\\*: (.+)\", text).group(1).strip()\n",
    "    equipment_id = re.search(r\"\\*\\*Equipment ID\\*\\*: (.+)\", text).group(1).strip()\n",
    "\n",
    "    # Create UC Delta table with unique index\n",
    "    data = [(idx, plant_id, equipment_name, equipment_id, text)]\n",
    "    columns = [\"id\", \"plantId\", \"equipmentName\", \"equipmentId\", \"markdown\"]\n",
    "\n",
    "    df = spark.createDataFrame(data, columns)\n",
    "\n",
    "    df.write.mode(\"append\").saveAsTable(f\"{catalog}.{schema}.{inspection_report_table_name}\")\n",
    "\n",
    "# needed for vector search index\n",
    "spark.sql(f\"ALTER TABLE `{catalog}`.`{schema}`.`{inspection_report_table_name}` SET TBLPROPERTIES (delta.enableChangeDataFeed = true)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5f778bc-d859-4486-8dfc-b75b37482daa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "endpoint_name = \"turnaround_vector_search_endpoint\"\n",
    "\n",
    "client = VectorSearchClient()\n",
    "\n",
    "client.create_endpoint(\n",
    "    name=endpoint_name,\n",
    "    endpoint_type=\"STANDARD\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1800faa0-a815-4a72-afc6-c79f04c979a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "vector_search_index_name = \"turnaround_inspection_reports_vs\"\n",
    "\n",
    "index = client.create_delta_sync_index(\n",
    "  endpoint_name=endpoint_name,\n",
    "  source_table_name=f\"{catalog}.{schema}.{inspection_report_table_name}\",\n",
    "  index_name=f\"{catalog}.{schema}.{vector_search_index_name}\",\n",
    "  pipeline_type=\"TRIGGERED\",\n",
    "  primary_key=\"id\",\n",
    "  embedding_source_column=\"markdown\",\n",
    "  embedding_model_endpoint_name=\"databricks-gte-large-en\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6214d806-69bc-4b2c-956f-eed4e577b62d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1421460868952071,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "00-setup (1)",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
