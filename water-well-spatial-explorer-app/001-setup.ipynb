{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dc04dcd3-4739-467e-a813-9c7d12049ec3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#001-setup\n",
    "### DO NOT MODIFY - RUN \"AS IS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "956c5834-8cec-4bef-80dd-730680815bfb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "626ec309-d3d8-4501-9aa5-ff5316e24a1a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2490b04a-e31a-40d5-93b4-afba48e08a5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalog = \"users\"\n",
    "schema = \"david_hurley\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99a14bf4-6b17-4d44-bf25-75647bdebbe0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"CREATE CATALOG IF NOT EXISTS {catalog}\"\"\")\n",
    "spark.sql(f\"\"\"CREATE SCHEMA IF NOT EXISTS {catalog}.{schema}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd3878f5-d207-435e-9e52-78df26834d30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create Delta table for non-partitioned csv\n",
    "csv_to_create_tables_for = [\n",
    "    \"alberta_wdrill_boreholes.csv\",\n",
    "    \"alberta_wdrill_driller_drilling_company.csv\",\n",
    "    \"alberta_wdrill_drillers.csv\",\n",
    "    \"alberta_wdrill_drilling_companies.csv\",\n",
    "    \"alberta_wdrill_other_seals.csv\",\n",
    "    \"alberta_wdrill_perforations.csv\",\n",
    "    \"alberta_wdrill_pump_test_items.csv\",\n",
    "    \"alberta_wdrill_screens.csv\",\n",
    "    \"alberta_wdrill_wells.csv\",\n",
    "    \"alberta_wtest_bacterio_analysis_info.csv\",\n",
    "    \"alberta_wtest_bacterio_details.csv\",\n",
    "    \"alberta_wtest_exceedances.csv\",\n",
    "    \"alberta_wtest_field_notes.csv\",\n",
    "    \"alberta_wtest_field_personnel.csv\",\n",
    "    \"alberta_wtest_gas_analysis_info.csv\",\n",
    "    \"alberta_wtest_gas_details.csv\",\n",
    "    \"alberta_wtest_gcdwq_standard.csv\",\n",
    "    \"alberta_wtest_iso_analysis_info.csv\",\n",
    "    \"alberta_wtest_iso_details.csv\",\n",
    "    \"alberta_wtest_well.csv\",\n",
    "    \"alberta_wtest_well_measures.csv\",\n",
    "    \"alberta_wtest_well_test.csv\",\n",
    "    \"alberta_wtest_wqual_analysis_info.csv\",\n",
    "    \"alberta_wtest_wqual_details.csv\",\n",
    "    \"alberta_wtest_yield_hour\",\n",
    "    \"alberta_wtest_yield_test.csv\",\n",
    "    \"alberta_wtest_yield_test_field_parameters.csv\"\n",
    "]\n",
    "\n",
    "for filename in csv_to_create_tables_for:\n",
    "    df = pd.read_csv(f\"../data/{filename}\", low_memory=False)\n",
    "    spark_df = spark.createDataFrame(df)\n",
    "    spark_df.write.mode(\"overwrite\").saveAsTable(f\"{catalog}.{schema}.{filename.split(\".csv\")[0]}\")\n",
    "    print(f\"Created {catalog}.{schema}.{filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52dbb5c9-df5d-4bbf-9ed5-0086786c3d0e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create Delta table for partitioned lithology\n",
    "df1 = pd.read_csv(\"../data/alberta_wdrill_lithologies_1.csv\", low_memory=False)\n",
    "df2 = pd.read_csv(\"../data/alberta_wdrill_lithologies_2.csv\", low_memory=False)\n",
    "combined_df = pd.concat([df1, df2], ignore_index=True, sort=False)\n",
    "\n",
    "spark_df = spark.createDataFrame(combined_df)\n",
    "spark_df.write.mode(\"overwrite\").saveAsTable(f\"{catalog}.{schema}.alberta_wdrill_lithologies\")\n",
    "print(f\"Created {catalog}.{schema}.alberta_wdrill_lithologies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6896c6b-af80-427d-8bc5-f31ee297b0a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create Delta table for partitioned well reports\n",
    "df1 = pd.read_csv(\"../data/alberta_wdrill_well_reports_1.csv\", low_memory=False)\n",
    "df2 = pd.read_csv(\"../data/alberta_wdrill_well_reports_2.csv\", low_memory=False)\n",
    "df3 = pd.read_csv(\"../data/alberta_wdrill_well_reports_3.csv\", low_memory=False)\n",
    "df4 = pd.read_csv(\"../data/alberta_wdrill_well_reports_4.csv\", low_memory=False)\n",
    "combined_df = pd.concat([df1, df2, df3, df4], ignore_index=True, sort=False)\n",
    "\n",
    "spark_df = spark.createDataFrame(combined_df)\n",
    "spark_df.write.mode(\"overwrite\").saveAsTable(f\"{catalog}.{schema}.alberta_wdrill_well_reports\")\n",
    "print(f\"Created {catalog}.{schema}.alberta_wdrill_well_reports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18e423f3-28c8-4694-b5e3-15adb2ac17be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create Delta table for well location and material depth combined - for easy spatial sql analysis. Group material to common names\n",
    "\n",
    "sql = f\"\"\"\n",
    "CREATE OR REPLACE TABLE {catalog}.{schema}.alberta_wdrill_combined_location_lithology AS\n",
    "SELECT \n",
    "    row_number() OVER (ORDER BY t1.Well_ID, t3.Depth) AS id,  -- auto-increment ID\n",
    "    t1.Well_ID,\n",
    "    t1.Longitude, \n",
    "    t1.Latitude, \n",
    "    t3.Depth AS Depth_Of_Material,\n",
    "    t3.Water_Bearing, \n",
    "    t3.Material,\n",
    "    CASE\n",
    "        WHEN t3.Material ILIKE '%Clay%' THEN 'Clay'\n",
    "        WHEN t3.Material ILIKE '%Sand%' THEN 'Sand'\n",
    "        WHEN t3.Material ILIKE '%Gravel%' THEN 'Gravel'\n",
    "        WHEN t3.Material ILIKE '%Silt%' THEN 'Silt'\n",
    "        WHEN t3.Material ILIKE '%Shale%' THEN 'Shale'\n",
    "        WHEN t3.Material ILIKE '%Coal%' THEN 'Coal'\n",
    "        WHEN t3.Material ILIKE '%Rock%' \n",
    "          OR t3.Material ILIKE '%Bedrock%' \n",
    "          OR t3.Material ILIKE '%Limestone%' \n",
    "          OR t3.Material ILIKE '%Granite%' \n",
    "          OR t3.Material ILIKE '%Sandstone%' THEN 'Rock'\n",
    "        WHEN t3.Material ILIKE '%Till%' THEN 'Till'\n",
    "        WHEN t3.Material ILIKE '%Topsoil%' THEN 'Topsoil'\n",
    "        WHEN t3.Material ILIKE '%Organic%' \n",
    "          OR t3.Material ILIKE '%Muskeg%' \n",
    "          OR t3.Material ILIKE '%Tarsand%' THEN 'Organic'\n",
    "        ELSE 'Other'\n",
    "    END AS Material_Category\n",
    "FROM {catalog}.{schema}.alberta_wdrill_wells AS t1\n",
    "INNER JOIN {catalog}.{schema}.alberta_wdrill_well_reports AS t2\n",
    "    ON t1.Well_ID = t2.Well_ID\n",
    "INNER JOIN {catalog}.{schema}.alberta_wdrill_lithologies AS t3\n",
    "    ON t2.Well_Report_ID = t3.Well_Report_ID\n",
    "\"\"\"\n",
    "spark.sql(sql)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f161ef45-61d2-4114-9b71-8def66c26f17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create Delta table for test well location and water quality combined - for easy spatial sql analysis\n",
    "\n",
    "sql = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE {catalog}.{schema}.alberta_wtest_well_combined_location_quality AS (\n",
    "    SELECT \n",
    "        t1.WELL_ID,\n",
    "        t1.LONGITUDE,\n",
    "        t1.LATTITUDE,\n",
    "        t4.PARAMETER_NAME,\n",
    "        t4.PARAMETER_VALUE\n",
    "    FROM {catalog}.{schema}.alberta_wtest_well AS t1\n",
    "    INNER JOIN {catalog}.{schema}.alberta_wtest_well_test AS t2 \n",
    "    ON t1.WELL_ID = t2.WELL_ID\n",
    "    INNER JOIN {catalog}.{schema}.alberta_wtest_wqual_details AS t3\n",
    "    ON t2.WELL_TEST_ID = t3.WELL_TEST_ID\n",
    "    INNER JOIN {catalog}.{schema}.alberta_wtest_wqual_analysis_info AS t4\n",
    "    ON t3.WQUAL_DETAILS_ID = t4.WQUAL_DETAILS_ID\n",
    "    )\n",
    "\"\"\"\n",
    "spark.sql(sql)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "001-setup",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
