{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29db9f58-c2ae-45c4-8617-aeb978ea332b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# ðŸš¨ Long-Running Databricks Tasks\n",
    "\n",
    "This notebook identifies jobs, queries, and clusters exceeding thresholds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ab45d4d-f875-4a42-ae4b-ccbb0822ace7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "job_threshold_minutes = float(dbutils.widgets.get(\"job_threshold_minutes\"))\n",
    "query_threshold_minutes = float(dbutils.widgets.get(\"query_threshold_minutes\"))\n",
    "cluster_threshold_hours = float(dbutils.widgets.get(\"cluster_threshold_hours\"))\n",
    "output_catalog = dbutils.widgets.get(\"output_catalog\")\n",
    "output_schema = dbutils.widgets.get(\"output_schema\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6faccbe-bc52-4f2a-b709-cea3e166eee0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Monitor for long-running Databricks tasks using REST API.\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "class RunningTasks:\n",
    "    \"\"\"Monitor long-running tasks across queries, jobs, and clusters.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        context = dbutils.notebook.entry_point.getDbutils().notebook().getContext()\n",
    "        self.hostname = context.apiUrl().get()\n",
    "        self.headers = {\"Authorization\": f\"Bearer {context.apiToken().get()}\"}\n",
    "        self.current_time_ms = int(time.time() * 1000)\n",
    "    \n",
    "    def _ms_to_utc(self, timestamp_ms: Optional[int]) -> Optional[datetime]:\n",
    "        if timestamp_ms and timestamp_ms > 0:\n",
    "            return datetime.utcfromtimestamp(timestamp_ms / 1000)\n",
    "        return None\n",
    "    \n",
    "    def _calculate_duration(self, start_time_ms: Optional[int], unit_divisor: int) -> float:\n",
    "        if start_time_ms:\n",
    "            return round((self.current_time_ms - start_time_ms) / unit_divisor, 2)\n",
    "        return 0.0\n",
    "    \n",
    "    def _api_call(self, url: str, params: dict) -> dict:\n",
    "        response = requests.get(url=url, data=json.dumps(params), headers=self.headers)\n",
    "        return response.json()\n",
    "    \n",
    "    def get_active_queries(self) -> pd.DataFrame:\n",
    "        url = f\"{self.hostname}/api/2.0/sql/history/queries\"\n",
    "        \n",
    "        running = self._api_call(url, {\"filter_by\": {\"statuses\": [\"RUNNING\"]}}).get('res', [])\n",
    "        queued = self._api_call(url, {\"filter_by\": {\"statuses\": [\"QUEUED\"]}}).get('res', [])\n",
    "        \n",
    "        data = [{\n",
    "            'query_id': q.get('query_id'),\n",
    "            'user_name': q.get('user_name'),\n",
    "            'executed_as_user_name': q.get('executed_as_user_name'),\n",
    "            'warehouse_id': q.get('warehouse_id'),\n",
    "            'state': q.get('status'),\n",
    "            'query_text': q.get('query_text'),\n",
    "            'start_time_utc': self._ms_to_utc(q.get('query_start_time_ms')),\n",
    "            'duration_minutes': self._calculate_duration(q.get('query_start_time_ms'), 60000)\n",
    "        } for q in running + queued]\n",
    "        \n",
    "        return pd.DataFrame(data)\n",
    "    \n",
    "    def get_active_jobs(self) -> pd.DataFrame:\n",
    "        url = f\"{self.hostname}/api/2.2/jobs/runs/list\"\n",
    "        runs = self._api_call(url, {\"active_only\": True}).get('runs', [])\n",
    "        \n",
    "        data = [{\n",
    "            'job_id': job.get('job_id'),\n",
    "            'run_id': job.get('run_id'),\n",
    "            'run_name': job.get('run_name'),\n",
    "            'creator_user_name': job.get('creator_user_name'),\n",
    "            'state': job.get('state', {}).get('life_cycle_state'),\n",
    "            'start_time_utc': self._ms_to_utc(job.get('start_time')),\n",
    "            'duration_minutes': self._calculate_duration(job.get('start_time'), 60000),\n",
    "            'run_page_url': job.get('run_page_url'),\n",
    "            'run_type': job.get('run_type')\n",
    "        } for job in runs]\n",
    "        \n",
    "        return pd.DataFrame(data)\n",
    "    \n",
    "    def get_active_clusters(self) -> pd.DataFrame:\n",
    "        url = f\"{self.hostname}/api/2.1/clusters/list\"\n",
    "        clusters = self._api_call(url, {\"filter_by\": {\"cluster_states\": [\"RUNNING\"]}}).get('clusters', [])\n",
    "        \n",
    "        data = []\n",
    "        for c in clusters:\n",
    "            autoscale = c.get('autoscale')\n",
    "            num_workers = f\"{autoscale.get('min_workers')}-{autoscale.get('max_workers')}\" if autoscale else str(c.get('num_workers', ''))\n",
    "            \n",
    "            data.append({\n",
    "                'cluster_id': c.get('cluster_id'),\n",
    "                'cluster_name': c.get('cluster_name'),\n",
    "                'creator_user_name': c.get('creator_user_name'),\n",
    "                'state': c.get('state'),\n",
    "                'start_time_utc': self._ms_to_utc(c.get('start_time')),\n",
    "                'uptime_hours': self._calculate_duration(c.get('start_time'), 3600000),\n",
    "                'cluster_source': c.get('cluster_source'),\n",
    "                'num_workers': num_workers\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0793133f-d687-4157-a618-8311cbf0bccf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "monitor = RunningTasks()\n",
    "active_queries = monitor.get_active_queries()\n",
    "active_jobs = monitor.get_active_jobs()\n",
    "active_clusters = monitor.get_active_clusters()\n",
    "\n",
    "active_queries_filtered = active_queries[active_queries['duration_minutes'] > query_threshold_minutes]\n",
    "spark_df = spark.createDataFrame(active_queries_filtered)\n",
    "spark_df.write.mode(\"overwrite\").saveAsTable(f\"{output_catalog}.{output_schema}.long_running_queries\")\n",
    "\n",
    "active_jobs_filtered = active_jobs[active_jobs['duration_minutes'] > job_threshold_minutes]\n",
    "spark_df = spark.createDataFrame(active_jobs_filtered)\n",
    "spark_df.write.mode(\"overwrite\").saveAsTable(f\"{output_catalog}.{output_schema}.long_running_jobs\")\n",
    "\n",
    "active_clusters_filtered = active_clusters[active_clusters['uptime_hours'] > cluster_threshold_hours]\n",
    "spark_df = spark.createDataFrame(active_clusters_filtered)\n",
    "spark_df.write.mode(\"overwrite\").saveAsTable(f\"{output_catalog}.{output_schema}.long_running_clusters\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4550026928661713,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "LongRunningTasks",
   "widgets": {
    "cluster_threshold_hours": {
     "currentValue": "4",
     "nuid": "ea0016f4-f323-4e25-8cd5-f8e5c66d2621",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "4",
      "label": "Cluster Threshold (hours)",
      "name": "cluster_threshold_hours",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "4",
      "label": "Cluster Threshold (hours)",
      "name": "cluster_threshold_hours",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    },
    "job_threshold_minutes": {
     "currentValue": "30",
     "nuid": "4a422d60-3e80-4bb7-9c9e-69c969fa7956",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "30",
      "label": "Job Threshold (minutes)",
      "name": "job_threshold_minutes",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "30",
      "label": "Job Threshold (minutes)",
      "name": "job_threshold_minutes",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    },
    "output_catalog": {
     "currentValue": "users",
     "nuid": "162af970-f0b5-4aab-a29b-807cb7e22aff",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "users",
      "label": "Output Catalog",
      "name": "output_catalog",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "users",
      "label": "Output Catalog",
      "name": "output_catalog",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    },
    "output_schema": {
     "currentValue": "david_hurley",
     "nuid": "7624ab7b-426f-4c76-bb9e-401160e635c7",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "david_hurley",
      "label": "Output Schema",
      "name": "output_schema",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "david_hurley",
      "label": "Output Schema",
      "name": "output_schema",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    },
    "query_threshold_minutes": {
     "currentValue": "15",
     "nuid": "1b43d651-018b-457c-8d21-3a9c1f796ce1",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "15",
      "label": "Query Threshold (minutes)",
      "name": "query_threshold_minutes",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "15",
      "label": "Query Threshold (minutes)",
      "name": "query_threshold_minutes",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
